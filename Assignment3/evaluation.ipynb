{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tags = pickle.load(open(\"unique_tags.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HMM_metrics.pkl\", \"rb\") as f:\n",
    "    hmm_metrics = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MLP_Word2Vec_metrics.pkl\", \"rb\") as f:\n",
    "    mlp1_metric = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"MLP_Glove_metrics.pkl\", \"rb\") as f:\n",
    "    mlp2_metric = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_metrics = hmm_metrics\n",
    "# all_metrics.extend(mlp1_metric)\n",
    "# all_metrics.extend(mlp2_metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_metrics(metrics):\n",
    "    \"\"\"\n",
    "    Metrics is an array of dictionaries with the following values:\n",
    "        \"accuracy\": Accuracy for all tags,\n",
    "        \"precision\": Precision for all tags\n",
    "        \"recall\": Recall for all tags\n",
    "        \"f1-score\": F1 score for all tags\n",
    "        \"cm\": Confusion Matrix\n",
    "        \"tagwise_precision\" : array of precision based on tag\n",
    "        \"tagwise_recall\": array of recall based on tag\n",
    "        \"tagwise_f1\": array of f1 scores based on tag,\n",
    "        \"model_name\": Display Name of the model,\n",
    "        \"model_df_name\": Name of the model to be stored in df columns \n",
    "    \"\"\"\n",
    "    num_models = len(metrics)\n",
    "    metric_df = pd.DataFrame(\n",
    "        {\n",
    "            \"model_name\": [metrics[i][\"model_name\"] for i in range(num_models)],\n",
    "            \"accuracy\": [metrics[i][\"accuracy\"] for i in range(num_models)],\n",
    "            \"precision\": [metrics[i][\"precision\"] for i in range(num_models)],\n",
    "            \"recall\": [metrics[i][\"recall\"] for i in range(num_models)],\n",
    "            \"f1-score\": [metrics[i][\"f1-score\"] for i in range(num_models)]\n",
    "        }\n",
    "    )\n",
    "    tagwise_metric_df = pd.DataFrame(\n",
    "        {\n",
    "            \"tag\": unique_tags\n",
    "            # \"precision\": [metrics[i][\"tagwise_precision\"] for i in range(num_models)],\n",
    "            # \"recall\": [metrics[i][\"tagwise_recall\"] for i in range(num_models)],\n",
    "            # \"f1-score\": [metrics[i][\"tagwise_f1\"] for i in range(num_models)]\n",
    "        }\n",
    "    )\n",
    "    for i in range(len(metrics)):\n",
    "        tagwise_metric_df[\"precision_\" + metrics[i][\"model_df_name\"]] = metrics[i][\"tagwise_precision\"]\n",
    "    for i in range(len(metrics)):\n",
    "        tagwise_metric_df[\"recall_\" + metrics[i][\"model_df_name\"]] = metrics[i][\"tagwise_recall\"]\n",
    "    for i in range(len(metrics)):\n",
    "        tagwise_metric_df[\"tagwise_\" + metrics[i][\"model_df_name\"]] = metrics[i][\"tagwise_f1\"]\n",
    "    return metric_df, tagwise_metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_df, tagwise_metric_df = compare_metrics(all_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HMM</td>\n",
       "      <td>0.934288</td>\n",
       "      <td>0.934971</td>\n",
       "      <td>0.934288</td>\n",
       "      <td>0.934629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HMM Optional</td>\n",
       "      <td>0.925617</td>\n",
       "      <td>0.925731</td>\n",
       "      <td>0.925617</td>\n",
       "      <td>0.925674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     model_name  accuracy  precision    recall  f1-score\n",
       "0           HMM  0.934288   0.934971  0.934288  0.934629\n",
       "1  HMM Optional  0.925617   0.925731  0.925617  0.925674"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tag</th>\n",
       "      <th>precision_HMM</th>\n",
       "      <th>precision_HMMb</th>\n",
       "      <th>recall_HMM</th>\n",
       "      <th>recall_HMMb</th>\n",
       "      <th>tagwise_HMM</th>\n",
       "      <th>tagwise_HMMb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADP</td>\n",
       "      <td>0.927881</td>\n",
       "      <td>0.885120</td>\n",
       "      <td>0.934325</td>\n",
       "      <td>0.950680</td>\n",
       "      <td>0.931088</td>\n",
       "      <td>0.915364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DET</td>\n",
       "      <td>0.932602</td>\n",
       "      <td>0.926729</td>\n",
       "      <td>0.936486</td>\n",
       "      <td>0.926712</td>\n",
       "      <td>0.933730</td>\n",
       "      <td>0.924853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NOUN</td>\n",
       "      <td>0.952553</td>\n",
       "      <td>0.916841</td>\n",
       "      <td>0.922200</td>\n",
       "      <td>0.938739</td>\n",
       "      <td>0.937121</td>\n",
       "      <td>0.927659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VERB</td>\n",
       "      <td>0.948148</td>\n",
       "      <td>0.950318</td>\n",
       "      <td>0.957994</td>\n",
       "      <td>0.945191</td>\n",
       "      <td>0.952887</td>\n",
       "      <td>0.947181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADJ</td>\n",
       "      <td>0.916944</td>\n",
       "      <td>0.900266</td>\n",
       "      <td>0.874352</td>\n",
       "      <td>0.862799</td>\n",
       "      <td>0.894771</td>\n",
       "      <td>0.878019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CONJ</td>\n",
       "      <td>0.968926</td>\n",
       "      <td>0.977792</td>\n",
       "      <td>0.996005</td>\n",
       "      <td>0.992252</td>\n",
       "      <td>0.981933</td>\n",
       "      <td>0.984830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>PRT</td>\n",
       "      <td>0.825178</td>\n",
       "      <td>0.870711</td>\n",
       "      <td>0.866165</td>\n",
       "      <td>0.667837</td>\n",
       "      <td>0.844828</td>\n",
       "      <td>0.746073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>0.918396</td>\n",
       "      <td>0.940170</td>\n",
       "      <td>0.948445</td>\n",
       "      <td>0.940852</td>\n",
       "      <td>0.931809</td>\n",
       "      <td>0.939346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ADV</td>\n",
       "      <td>0.941688</td>\n",
       "      <td>0.935577</td>\n",
       "      <td>0.880705</td>\n",
       "      <td>0.866358</td>\n",
       "      <td>0.910157</td>\n",
       "      <td>0.899586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NUM</td>\n",
       "      <td>0.875749</td>\n",
       "      <td>0.917480</td>\n",
       "      <td>0.871675</td>\n",
       "      <td>0.708741</td>\n",
       "      <td>0.872721</td>\n",
       "      <td>0.797294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PRON</td>\n",
       "      <td>0.984172</td>\n",
       "      <td>0.989887</td>\n",
       "      <td>0.924222</td>\n",
       "      <td>0.887790</td>\n",
       "      <td>0.953145</td>\n",
       "      <td>0.934291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>X</td>\n",
       "      <td>0.737916</td>\n",
       "      <td>0.746389</td>\n",
       "      <td>0.291296</td>\n",
       "      <td>0.198726</td>\n",
       "      <td>0.414717</td>\n",
       "      <td>0.312045</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tag  precision_HMM  precision_HMMb  recall_HMM  recall_HMMb  tagwise_HMM  \\\n",
       "0    ADP       0.927881        0.885120    0.934325     0.950680     0.931088   \n",
       "1    DET       0.932602        0.926729    0.936486     0.926712     0.933730   \n",
       "2   NOUN       0.952553        0.916841    0.922200     0.938739     0.937121   \n",
       "3   VERB       0.948148        0.950318    0.957994     0.945191     0.952887   \n",
       "4    ADJ       0.916944        0.900266    0.874352     0.862799     0.894771   \n",
       "5   CONJ       0.968926        0.977792    0.996005     0.992252     0.981933   \n",
       "6    PRT       0.825178        0.870711    0.866165     0.667837     0.844828   \n",
       "7      .       0.918396        0.940170    0.948445     0.940852     0.931809   \n",
       "8    ADV       0.941688        0.935577    0.880705     0.866358     0.910157   \n",
       "9    NUM       0.875749        0.917480    0.871675     0.708741     0.872721   \n",
       "10  PRON       0.984172        0.989887    0.924222     0.887790     0.953145   \n",
       "11     X       0.737916        0.746389    0.291296     0.198726     0.414717   \n",
       "\n",
       "    tagwise_HMMb  \n",
       "0       0.915364  \n",
       "1       0.924853  \n",
       "2       0.927659  \n",
       "3       0.947181  \n",
       "4       0.878019  \n",
       "5       0.984830  \n",
       "6       0.746073  \n",
       "7       0.939346  \n",
       "8       0.899586  \n",
       "9       0.797294  \n",
       "10      0.934291  \n",
       "11      0.312045  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagwise_metric_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "220f31919fc022d292a5f800c84cebb2982377f1f20223b2735d9f41a3ba9d0f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('nlp': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
